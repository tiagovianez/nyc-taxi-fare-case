# Case de Engenharia de Dados  - EITS MLOps Engineering - Serasa Experian

1. Primeiro suba os serviÃ§os utilizando o docker compose file utilizando o terminal: **"docker compose up --build -d"**
2. Crie um tÃ³pico kafka utilizando executando esse comando: **docker exec -it nyc-taxi-case-kafka-1 sh -c "/opt/bitnami/kafka/bin/kafka-topics.sh --create --topic nyc-taxi-rides --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1"**
3. ApÃ³s isso, **liste os tÃ³picos no container do Kafka via docker** : **docker exec -it nyc-taxi-case-kafka-1 sh -c "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list"**. Isso serÃ¡ interessante para validar que o tÃ³pico kafka que irÃ¡ receber as mensagens estÃ¡ disponÃ­vel.
4. Checado isso, vÃ¡ atÃ© o diretÃ³rio "**/nyc-taxi-fare-case/nyctaxi**" via terminal e execute o comando para startar o Producer **sbt "runMain fare.nyctaxi.producer.KafkaTaxiProducer"**
5. [Opicional] Caso vocÃª necessite checar os eventos do tÃ³pico kafka, sÃ³ executar o comando no terminal: **docker exec -it nyc-taxi-case-kafka-1 sh -c "/opt/bitnami/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic nyc-taxi-rides"**. Isso irÃ¡ permitir que vocÃª consiga visualizar as novas mensagens enviadas.


## Comandos de execuÃ§Ã£o e validaÃ§Ã£o
- Para executar o producer: **sbt "runMain fare.nyctaxi.producer.KafkaTaxiProducer"**
- Para executar o consumer: **sbt "runMain fare.nyctaxi.consumer.TaxiConsumer"**


## ğŸ“Œ Como fica a estrutura no Data Lake?
![img.png](img.png)

## ğŸš€ Vantagens dessa abordagem
âœ… Consultas rÃ¡pidas â†’ Spark lÃª apenas os arquivos necessÃ¡rios
âœ… Menos armazenamento desperdiÃ§ado â†’ Evita pequenos arquivos dispersos
âœ… Escalabilidade â†’ Aguenta grandes volumes de dados sem travar
âœ… IntegraÃ§Ã£o com batch e NRT â†’ Pode rodar queries analÃ­ticas e streaming