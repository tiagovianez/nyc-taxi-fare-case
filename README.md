# Case de Engenharia de Dados  - EITS MLOps Engineering - Serasa Experian

1. Primeiro suba os servi√ßos utilizando o docker compose file utilizando o terminal: **"docker compose up --build -d"**
2. Crie um t√≥pico kafka utilizando executando esse comando: **docker exec -it kafka sh -c "/opt/bitnami/kafka/bin/kafka-topics.sh --create --topic nyc-taxi-rides --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1"**
3. Ap√≥s isso, liste os t√≥picos no container do Kafka via docker : **docker exec -it kafka sh -c "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list"**. Isso ser√° interessante para validar que o t√≥pico kafka que ir√° receber as mensagens est√° dispon√≠vel.
4. Checado isso, v√° at√© o diret√≥rio "**/nyc-taxi-fare-case/nyctaxi**" via terminal e execute o comando para startar o Producer **sbt "runMain fare.nyctaxi.producer.ProducerJob"**
5. [Opicional] Caso voc√™ necessite checar os eventos do t√≥pico kafka, s√≥ executar o comando no terminal: **docker exec -it kafka sh -c "/opt/bitnami/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic nyc-taxi-rides"**. Isso ir√° permitir que voc√™ consiga visualizar as novas mensagens enviadas.


## Comandos de execu√ß√£o e valida√ß√£o
- Para executar o producer: **sbt "runMain fare.nyctaxi.producer.KafkaTaxiProducer"**
- Para executar o consumer: **sbt "runMain fare.nyctaxi.consumer.TaxiConsumer"**


## üìå Como fica a estrutura no Data Lake?
![img.png](img.png)

## üöÄ Vantagens dessa abordagem
‚úÖ Consultas r√°pidas ‚Üí Spark l√™ apenas os arquivos necess√°rios
‚úÖ Menos armazenamento desperdi√ßado ‚Üí Evita pequenos arquivos dispersos
‚úÖ Escalabilidade ‚Üí Aguenta grandes volumes de dados sem travar
‚úÖ Integra√ß√£o com batch e NRT ‚Üí Pode rodar queries anal√≠ticas e streaming




## Analysys memory

### amout of data stored in the raw: 354.8MB
### amount of data stored in the curated: 457.8MB



## Airfllow comandos
üîπ Comandos Airflow

**airflow db upgrade** ‚Üí Atualiza o banco de dados.
**airflow users create** ... ‚Üí Cria um usu√°rio administrador.
**airflow scheduler** & **airflow webserver** ‚Üí Inicia os servi√ßos do Airflow.
**docker logs -f nyc-taxi-fare-case-airflow-1** -> Verifica as logs do airflow


## Comandos do docker
**docker volume ls** -> Verifica se ainda tem volume ativo
**docker volume rm <service_data>** -> remove manualmente o volume do servi√ßo




## SBT configura√ß√µes:

1. Configurar SBT_OPTS para aumentar a mem√≥ria

Antes de rodar o sbt assembly, execute o seguinte comando no terminal para aumentar a mem√≥ria dispon√≠vel:

export SBT_OPTS="-Xms2G -Xmx4G -XX:MaxMetaspaceSize=1G -XX:+UseG1GC"